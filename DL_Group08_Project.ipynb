{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import split_folders\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- CONFIG ---------#\n",
    "batch_size = 32\n",
    "#--------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folders.ratio('raw_dataset_face_mask', output=\"dataset_face_mask\", seed=2020, ratio=(.70, .15, .15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = pathlib.Path(\"./dataset_face_mask/\")\n",
    "train_dir = data_dir / \"train\"\n",
    "val_dir   = data_dir / \"val\"\n",
    "test_dir  = data_dir / \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize every image to 96x96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(data_dir.glob('**/*.png')):\n",
    "    im = Image.open(filename)\n",
    "    imResize = im.resize((96, 96), Image.ANTIALIAS)\n",
    "    imResize.save(filename, 'PNG', quality=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Create ImageDataGenerators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGenerator = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "gen_args = {\"target_size\": (96, 96),\n",
    "            \"batch_size\": batch_size,\n",
    "            \"classes\": [\"WithoutMask\", \"WithMask\"],\n",
    "            \"seed\": 2020,\n",
    "            \"color_mode\": \"rgb\",\n",
    "            \"class_mode\": \"binary\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train, Validation and Test ImageDataGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = imageGenerator.flow_from_directory(directory = train_dir, shuffle = True,  **gen_args)\n",
    "val_data   = imageGenerator.flow_from_directory(directory = val_dir,   shuffle = True,  **gen_args)\n",
    "test_data  = imageGenerator.flow_from_directory(directory = test_dir,  shuffle = False, **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "train_data.class_indices, val_data.class_indices, test_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    graph = tf.get_default_graph()\n",
    "    K.clear_session()  # Clear previous models from memory to avoid conflicts with previous sessions\n",
    "    sess = tf.Session()\n",
    "    K.set_session(sess)\n",
    "except:\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callbacks import EarlyStopping, ReduceLROnPlateau, MakeLRGreatAgain, ModelCheckpoint, BetterCSVLogger, TerminateOnNaN #, LearningRateScheduler\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 80: return 0.001\n",
    "    elif epoch < 100: return 0.0001\n",
    "    else: return 0.00001\n",
    "\n",
    "# Define model callbacks.\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.0, patience=115, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=20, verbose=1, min_delta=0.001, cooldown=0, min_lr=0.00001),\n",
    "    MakeLRGreatAgain(monitor='val_loss', factor_min=10, factor_max=100, patience=59, verbose=1, min_delta=0.001, cooldown=0, min_lr=0.00001),\n",
    "#     LearningRateScheduler(schedule=lr_schedule, verbose=1),\n",
    "    ModelCheckpoint(filepath=\"./weights/epoch{epoch:02d}_loss{loss:.4f}_val{val_loss:.4f}.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                    save_weights_only=False, mode='auto', period=1),\n",
    "    BetterCSVLogger(filename=f\"./log/training_log.csv\", separator=',', append=True),\n",
    "    TerminateOnNaN(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Keras Model - Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf_adam = Sequential([Conv2D(32, (3, 3), input_shape = (96, 96, 3), activation = 'relu'),\n",
    "                             MaxPooling2D(pool_size = (2, 2)),\n",
    "                             Conv2D(32, (3, 3), activation = 'relu'),\n",
    "                             GlobalAveragePooling2D(),\n",
    "                             Dense(1, activation='sigmoid')])\n",
    "\n",
    "model_clf_rmsprop = Sequential([Conv2D(32, (3, 3), input_shape = (96, 96, 3), activation = 'relu'),\n",
    "                                MaxPooling2D(pool_size = (2, 2)),\n",
    "                                Conv2D(32, (3, 3), activation = 'relu'),\n",
    "                                GlobalAveragePooling2D(),\n",
    "                                Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf_adam.compile(optimizer= \"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_clf_rmsprop.compile(optimizer= \"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_clf_adam = model_clf_adam.fit_generator(train_data,\n",
    "                                                steps_per_epoch = np.ceil(train_data.samples/batch_size),\n",
    "                                                epochs = 1000,\n",
    "                                                validation_data = val_data,\n",
    "                                                validation_steps = np.ceil(val_data.samples/batch_size),\n",
    "                                                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_clf_rmsprop = model_clf_rmsprop.fit_generator(train_data,\n",
    "                                                      steps_per_epoch = np.ceil(train_data.samples/batch_size),\n",
    "                                                      epochs = 1000,\n",
    "                                                      validation_data = val_data,\n",
    "                                                      validation_steps = np.ceil(val_data.samples/batch_size),\n",
    "                                                      callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "acc_adam     = history_clf_adam.history[\"acc\"][5:]\n",
    "val_acc_adam = history_clf_adam.history[\"val_acc\"][5:]\n",
    "epochs_adam  = range(len(acc_adam))\n",
    "\n",
    "acc_rmsprop     = history_clf_rmsprop.history[\"acc\"][5:]\n",
    "val_acc_rmsprop = history_clf_rmsprop.history[\"val_acc\"][5:]\n",
    "epochs_rmsprop  = range(len(acc_rmsprop))\n",
    "\n",
    "plt.plot(epochs_adam, acc_adam, \"bo\", label = \"Training acc - Adam\")\n",
    "plt.plot(epochs_adam, val_acc_adam, \"b\", label = \"Validation acc - Adam\")\n",
    "plt.plot(epochs_rmsprop, acc_rmsprop, \"ro\", label = \"Training acc - RMSProp\")\n",
    "plt.plot(epochs_rmsprop, val_acc_rmsprop, \"r\", label = \"Validation acc - RMSProp\")\n",
    "plt.title(\"Adam/RMSProp optimizers comparison (Accuracy)\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "# plot Loss\n",
    "loss_adam     = history_clf_adam.history[\"loss\"][5:]\n",
    "val_loss_adam = history_clf_adam.history[\"val_loss\"][5:]\n",
    "\n",
    "loss_rmsprop     = history_clf_rmsprop.history[\"loss\"][5:]\n",
    "val_loss_rmsprop = history_clf_rmsprop.history[\"val_loss\"][5:]\n",
    "\n",
    "plt.plot(epochs_adam, loss_adam, \"bo\", label = \"Training loss - Adam\")\n",
    "plt.plot(epochs_adam, val_loss_adam, \"b\", label = \"Validation loss - Adam\")\n",
    "plt.plot(epochs_rmsprop, loss_rmsprop, \"ro\", label = \"Training loss - RMSProp\")\n",
    "plt.plot(epochs_rmsprop, val_loss_rmsprop, \"r\", label = \"Validation loss - RMSProp\")\n",
    "plt.title(\"Adam/RMSProp optimizers comparison (Loss)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnv2 = MobileNetV2(input_shape = (96, 96, 3), include_top = False, weights = \"imagenet\")\n",
    "\n",
    "model_mnv2 = Sequential([\n",
    "    mnv2,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1, activation=\"sigmoid\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnv2.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mnv2 = model_mnv2.fit_generator(train_data,\n",
    "                                        steps_per_epoch = np.ceil(train_data.samples/batch_size),\n",
    "                                        epochs = 1000,\n",
    "                                        validation_data = val_data,\n",
    "                                        validation_steps = np.ceil(val_data.samples/batch_size),\n",
    "                                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mnv2      = history_mnv2.history[\"acc\"][:5]\n",
    "val_acc_mnv2  = history_mnv2.history[\"val_acc\"][:5]\n",
    "loss_mnv2     = history_mnv2.history[\"loss\"][:5]\n",
    "val_loss_mnv2 = history_mnv2.history[\"val_loss\"][:5]\n",
    "epochs_mnv2   = range(len(acc_mnv2))\n",
    "\n",
    "plt.plot(epochs_mnv2, acc_mnv2, \"bo\", label = \"Training acc - MobileNetV2\")\n",
    "plt.plot(epochs_mnv2, val_acc_mnv2, \"b\", label = \"Validation acc - MobileNetV2\")\n",
    "plt.plot(epochs_rmsprop, acc_rmsprop, \"ro\", label = \"Training acc - RMSProp\")\n",
    "plt.plot(epochs_rmsprop, val_acc_rmsprop, \"r\", label = \"Validation acc - RMSProp\")\n",
    "plt.title(\"Classifier/MobileNetV2 performance comparison (Accuracy)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs_mnv2, loss_mnv2, \"bo\", label = \"Training loss\")\n",
    "plt.plot(epochs_mnv2, val_loss_mnv2, \"b\", label = \"Validation loss\")\n",
    "plt.plot(epochs_rmsprop, loss_rmsprop, \"ro\", label = \"Training loss - RMSProp\")\n",
    "plt.plot(epochs_rmsprop, val_loss_rmsprop, \"r\", label = \"Validation loss - RMSProp\")\n",
    "plt.title(\"Classifier/MobileNetV2 performance comparison (Loss)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_path(path):\n",
    "    bestLoss = int(9e9)\n",
    "    lastEpoch = int(9e9)\n",
    "    bestWeights = \"\"\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        valLoss = float(file.split(\"val\")[1].split(\".h5\")[0])\n",
    "        epoch = int(file.split(\"_loss\")[0].split(\"epoch\")[1])\n",
    "        if (valLoss < bestLoss) or ((valLoss == bestLoss) and (epoch > lastEpoch)):\n",
    "            bestLoss = valLoss\n",
    "            lastEpoch = epoch\n",
    "            bestWeights = f\"{path}{file}\"\n",
    "    \n",
    "    if bestWeights == \"\": raise FileNotFoundError(f\"There is no model saved in `{weights_dir}`...\")\n",
    "            \n",
    "    return bestWeights\n",
    "\n",
    "bestWeights = get_weights_path(\"./weights/\")\n",
    "print(bestWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = load_model(bestWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with `clf_adam` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_adam = model_clf_adam.predict_generator(test_data, steps = np.ceil(test_data.samples/batch_size))\n",
    "preds_adam = preds_adam.astype(np.int32).reshape(test_data.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with `clf_rmsprop` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rmsprop = model_clf_rmsprop.predict_generator(test_data, steps = np.ceil(test_data.samples/batch_size))\n",
    "preds_rmsprop = preds_rmsprop.astype(np.int32).reshape(test_data.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with `mnv2` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mnv2 = model_mnv2.predict_generator(test_data, steps = np.ceil(test_data.samples/batch_size))\n",
    "preds_mnv2 = preds_mnv2.astype(np.int32).reshape(test_data.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate `clf_adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Confusion matrix:\\n\\n{confusion_matrix(test_data.labels, preds_adam, labels=[0, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy = {round(accuracy_score(test_data.labels, preds_adam) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification report:\\n\\n{classification_report(test_data.labels, preds_adam, target_names=test_data.class_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate `clf_rmsprop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Confusion matrix:\\n\\n{confusion_matrix(test_data.labels, preds_rmsprop, labels=[0, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy = {round(accuracy_score(test_data.labels, preds_rmsprop) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification report:\\n\\n{classification_report(test_data.labels, preds_rmsprop, target_names=test_data.class_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate `mnv2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Confusion matrix:\\n\\n{confusion_matrix(test_data.labels, preds_mnv2, labels=[0, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy = {round(accuracy_score(test_data.labels, preds_mnv2) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification report:\\n\\n{classification_report(test_data.labels, preds_mnv2, target_names=test_data.class_indices)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
